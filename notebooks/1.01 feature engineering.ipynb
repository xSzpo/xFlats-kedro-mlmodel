{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = catalog.load('model_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[df.split == 'train'].drop(columns=['split','price']).reset_index(drop=True)\n",
    "X_test = df.loc[df.split == 'test'].drop(columns=['split','price']).reset_index(drop=True)\n",
    "X_valid = df.loc[df.split == 'valid'].drop(columns=['split','price']).reset_index(drop=True)\n",
    "\n",
    "y_train = df.loc[df.split == 'train'].price.reset_index(drop=True)\n",
    "y_test = df.loc[df.split == 'test'].price.reset_index(drop=True)\n",
    "y_valid = df.loc[df.split == 'valid'].price.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['producer_name','market','building_type','building_material','property_form','offeror',\n",
    "              'GC_addr_suburb','GC_addr_postcode']\n",
    "numerical = ['flat_size', 'rooms', 'floor', 'number_of_floors', 'year_of_building',\n",
    "             'GC_latitude', 'GC_longitude', 'price_median_08w']\n",
    "numerical_add = ['price_median_01w', 'price_median_02w',\n",
    "             'price_median_03w', 'price_median_04w',\n",
    "             'price_median_12w', 'price_mean_01w', 'price_mean_02w',\n",
    "             'price_mean_03w', 'price_mean_04w', 'price_mean_08w', 'price_mean_12w']\n",
    "\n",
    "text = ['location','description','name','additional_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.select_dtypes('number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-measure",
   "metadata": {},
   "source": [
    "## Text features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-jerusalem",
   "metadata": {},
   "source": [
    "### description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "\n",
    "import category_encoders as ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='wyjatkowa oferta gotowych i wykonczonych apartamentow zapraszam serdecznie do ogladania ! nowoczesnie urzadzone apartamenty o powierzchni od 21m2 do 55 m2 poozone w zachodniej czesci warszawy, przy al. jerozolimskich. mniejsze apartamenty skadaja sie z salonu z aneksem kuchennym i azienki, wieksze posiadaja dodatkowa sypialnie i druga azienke. niezwykle atrakcyjnie wykonczone, blisko miedzynarodowego lotniska im. fryderyka chopina i dworca kolejowego, doskonale skomunikowane z centrum warszawy i drogami wyjazdowymi. posiadam rowniez inne ukady mieszkan w tej oraz sasiednich inwestycjach oferta 1-2-3-4-5-6 pokoi o metrazach 15 - 190 m2. w cenach juz od 200 000 z - idealne rozwiazania dla inwestorow zapraszam po szczegoowe informacje - tel 501-920-939'\n",
    "\n",
    "\n",
    "reg = r'[A-Za-z]\\w{2,}'\n",
    "r1 = re.findall(reg,text)\n",
    "r1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def preProcess(s):\n",
    "    return unidecode(s).lower()\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    ColumnTransformer([\n",
    "        ('txt_description', TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            ngram_range=(1, 3),\n",
    "            stop_words = ['ale','oraz','lub','sie','and','the','jest','do','od'],\n",
    "            max_features=1000,\n",
    "            token_pattern=r'[A-Za-z]\\w{2,}',\n",
    "            preprocessor = preProcess,\n",
    "            dtype=np.float32,\n",
    "            use_idf=True,\n",
    "        ), 'description'),\n",
    "    ]),\n",
    "    lgb.LGBMRegressor(objective='regression_l2', random_state=666)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.metrics import r2_score, median_absolute_error\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "med_abs_err = median_absolute_error(y_train, y_pred)\n",
    "mean_abs_err = mean_absolute_error(y_train, y_pred)\n",
    "print(\"Train set r2 score {}, median absolute error {}, \"\n",
    "      \"mean absolute error {}\".format(round(r2, 4), int(med_abs_err),\n",
    "                                      int(mean_abs_err)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-albania",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from eli5 import show_weights, explain_weights_lightgbm\n",
    "explain_weights_lightgbm(pipe.named_steps['lgbmregressor'], \n",
    "             feature_names = pipe.named_steps['columntransformer'].get_feature_names(),\n",
    "             top=50,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "best_pred = X_train.loc[np.abs(y_train - y_pred) < 1000, 'description']\n",
    "eli5.explain_prediction(pipe.named_steps['lgbmregressor'],\n",
    "                        best_pred.iloc[1], \n",
    "                        vec=pipe.named_steps['columntransformer'].named_transformers_['txt_description'], \n",
    "                        top = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "best_pred = X_train.loc[np.abs(y_train - y_pred) < 1000, 'description']\n",
    "eli5.explain_prediction(pipe.named_steps['lgbmregressor'],\n",
    "                        best_pred.iloc[7], \n",
    "                        vec=pipe.named_steps['columntransformer'].named_transformers_['txt_description'], \n",
    "                        top = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-jungle",
   "metadata": {},
   "source": [
    "### name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def preProcess(s):\n",
    "    return unidecode(s).lower()\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    ColumnTransformer([\n",
    "        ('txt_name', TfidfVectorizer(lowercase=True, \n",
    "                               ngram_range=(1,1), \n",
    "                               stop_words = ['ale','oraz','lub','sie','and','the','jest','do','od'],\n",
    "                               max_features=500,\n",
    "                               token_pattern=r'[A-Za-z]\\w{2,}',                               \n",
    "                               dtype=np.float32,\n",
    "                               binary = True, \n",
    "                               preprocessor=preProcess,\n",
    "                               use_idf=False), 'name'),\n",
    "    ]),\n",
    "    lgb.LGBMRegressor(objective='regression_l2', random_state=666)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.metrics import r2_score, median_absolute_error\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "med_abs_err = median_absolute_error(y_train, y_pred)\n",
    "mean_abs_err = mean_absolute_error(y_train, y_pred)\n",
    "print(\"Train set r2 score {}, median absolute error {}, \"\n",
    "      \"mean absolute error {}\".format(round(r2, 4), int(med_abs_err),\n",
    "                                      int(mean_abs_err)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5 import show_weights, explain_weights_lightgbm\n",
    "explain_weights_lightgbm(pipe.named_steps['lgbmregressor'], \n",
    "             feature_names = pipe.named_steps['columntransformer'].get_feature_names(),\n",
    "             top=50,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-nebraska",
   "metadata": {},
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import category_encoders as ce\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "cols_ce_oh = ['producer_name', 'market', 'building_type', 'building_material', 'property_form', 'offeror']\n",
    "cols_ce_te = ['GC_addr_suburb', 'GC_addr_postcode']\n",
    "cols_numeric = ['flat_size', 'rooms', 'floor', 'number_of_floors', 'year_of_building','GC_latitude', \n",
    "                'GC_longitude']\n",
    "\n",
    "cols_prices_in_neighbourhood = ['price_median_03w', 'price_median_08w','price_median_12w', \n",
    "                                'price_mean_03w', 'price_mean_08w', 'price_mean_12w']\n",
    "\n",
    "stop_words = ['ale','oraz','lub','sie','and','the','jest','do','od','with','mozna']\n",
    "\n",
    "token_pattern=r'[A-Za-z]\\w{2,}'\n",
    "\n",
    "def preProcess(s):\n",
    "    return unidecode(s).lower()\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    ColumnTransformer([\n",
    "        ('ce_oh',ce.OneHotEncoder(return_df=True, use_cat_names=True),cols_ce_oh),\n",
    "        ('ce_GC',ce.TargetEncoder(return_df=True),cols_ce_te),\n",
    "        ('numeric','passthrough',cols_numeric+cols_prices_in_neighbourhood),\n",
    "        ('txt_description', TfidfVectorizer(lowercase=True,\n",
    "                                            ngram_range=(1, 3),\n",
    "                                            stop_words = stop_words,\n",
    "                                            max_features=1000,\n",
    "                                            token_pattern=token_pattern,\n",
    "                                            preprocessor = preProcess,\n",
    "                                            dtype=np.float32,\n",
    "                                            use_idf=True,\n",
    "                                           ), 'description'),\n",
    "        ('txt_name', TfidfVectorizer(lowercase=True,\n",
    "                                     ngram_range=(1,1), \n",
    "                                     stop_words = stop_words,\n",
    "                                     max_features=500,\n",
    "                                     token_pattern=token_pattern,                               \n",
    "                                     dtype=np.float32,\n",
    "                                     binary = True, \n",
    "                                     preprocessor=preProcess,\n",
    "                                     use_idf=False\n",
    "                                    ), 'name'),\n",
    "    ]),\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-surface",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_transformed = pipe.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-chemical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train_transformed.npy', 'wb') as f:\n",
    "    np.save(f, X_train_transformed, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train_transformed.npy', 'rb') as f:\n",
    "    x=np.load(f, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.LGBMRegressor(objective='regression_l2', random_state=666)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.metrics import r2_score, median_absolute_error\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "med_abs_err = median_absolute_error(y_train, y_pred)\n",
    "mean_abs_err = mean_absolute_error(y_train, y_pred)\n",
    "print(\"Train set r2 score {}, median absolute error {}, \"\n",
    "      \"mean absolute error {}\".format(round(r2, 4), int(med_abs_err),\n",
    "                                      int(mean_abs_err)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-moisture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.metrics import r2_score, median_absolute_error\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "med_abs_err = median_absolute_error(y_test, y_pred_test)\n",
    "mean_abs_err = mean_absolute_error(y_test, y_pred_test)\n",
    "print(\"Train set r2 score {}, median absolute error {}, \"\n",
    "      \"mean absolute error {}\".format(round(r2, 4), int(med_abs_err),\n",
    "                                      int(mean_abs_err)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "\n",
    "print('Plotting feature importances...')\n",
    "def names(): return pipe.named_steps['columntransformer'].get_feature_names()\n",
    "pipe.named_steps['lgbmregressor'].booster_.feature_name = names\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "fig.subplots_adjust(left=0.4)\n",
    "lgb.plot_importance(pipe.named_steps['lgbmregressor'], max_num_features=35, ax=ax, importance_type = 'split')\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-genius",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "premier-rover",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cat = dict()\n",
    "for cat in categorical:\n",
    "    dict_cat[cat] = preprocessing.LabelEncoder()\n",
    "    X_train.loc[0, cat] = 'n/a'\n",
    "    dict_cat[cat].fit(X_train[cat])\n",
    "    X_train[cat] = dict_cat[cat].transform(X_train[cat])\n",
    "    X_test[cat] = [i if i in list(dict_cat[cat].classes_) else 'n/a' for i in X_test[cat]]\n",
    "    X_test[cat] = dict_cat[cat].transform(X_test[cat])\n",
    "    X_valid[cat] = [i if i in list(dict_cat[cat].classes_) else 'n/a' for i in X_valid[cat]]\n",
    "    X_valid[cat] = dict_cat[cat].transform(X_valid[cat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(\n",
    "    X_train[categorical+numerical],\n",
    "    label=y_train,\n",
    "    categorical_feature=categorical,\n",
    "    free_raw_data=False\n",
    "            )\n",
    "\n",
    "test_data = lgb.Dataset(\n",
    "    X_test[categorical+numerical],\n",
    "    label=y_test,\n",
    "    reference = train_data,\n",
    "    categorical_feature=categorical,\n",
    "    free_raw_data=False\n",
    "            )\n",
    "\n",
    "validation_data = lgb.Dataset(\n",
    "    X_valid[categorical+numerical],\n",
    "    label=y_valid,\n",
    "    categorical_feature=categorical,\n",
    "    free_raw_data=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_PARAMS={'objective': 'regression',\n",
    "              'metric': 'regression_l1',\n",
    "              'boosting':'gbdt',\n",
    "              'num_boost_round':100,\n",
    "              'metric':['mape','l1'],\n",
    "              'early_stopping_rounds':20}\n",
    "\n",
    "SEARCH_PARAMS = {'learning_rate': 0.05,\n",
    "                'max_depth': 15,\n",
    "                'num_leaves': 100,\n",
    "                'feature_fraction': 0.8,\n",
    "                'subsample': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_PARAMS.update(SEARCH_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-locator",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bst = lgb.train(FIXED_PARAMS, train_data, valid_sets=[test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.best_score['valid_0']['mape']\n",
    "bst.best_score['valid_0']['l1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = bst.predict(X_train[categorical+numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "lgb.plot_importance(bst, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-stake",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,  bst.predict(X_test[categorical+numerical]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_valid,  bst.predict(X_valid[categorical+numerical]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xflats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
